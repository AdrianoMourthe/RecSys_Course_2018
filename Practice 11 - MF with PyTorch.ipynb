{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2022/2023\n",
    "\n",
    "## Practice Session 11 - MF with PyTorch\n",
    "\n",
    "PyTorch, Tensorflow, Keras are useful framework that allow you to build machine learning models (from linear regression to complex deep learning methods) and hide almost all of the complexity related to the training. Usually, you only have to create an object that starting from the model parameters will be able to compute your prediction, then specify the loss and the framework automatically calculates the gradients.\n",
    "\n",
    "#### Performance warning!\n",
    "In image processing tasks one usually has an image, maybe a reasonably large one (1000x1000x3, hence 3\\*10^6 data points) on which a complex network is applied (multiple convolution operations, pooling etc). The computationally expensive part can be effectively parallelized by the framework and hence the speedup over using single-core operations is massive.\n",
    "\n",
    "Unfortunately here we are not dealing with images, but with user profiles. In terms of data this means each profile can be in the 10^5 - 10^6 items. The issue arises when considering the model. If you use a matrix factorization model, the core of the operation is a dot product between two embedding vectors, which is an extremely fast operation. There is hardly any speedup and the burden of the overall infrastructure is not offset by it. For this reason, if you use a profiler you will see that 80-90% of the time is spent in the data sampling phase (because it is done in python it can be quite slow) and the actual prediction computation is a tiny fraction of the time. Overall, a *simple* matrix factorization model may be 10x slower if implemented with pytorch. The gap will reduce if you use a powerful GPU but I am yet to find someone able to run that on a GPU faster than the Cython single-core implementation.\n",
    "\n",
    "#### Prototyping\n",
    "Given how the complexity of gradients and such is hidden, pytorch becomes a great tool for prototyping. It is very easy to change someting in your model becayse you do not need to dig in Cython code. For example, you may implement a SLIM MSE method that uses as inital parameters the similarity computed with an item-based cosine method, or you may create a hybrid of multiple similarities and lear the weights to use for each similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What do we need\n",
    "\n",
    "* A Dataset object to load the data\n",
    "* Model object\n",
    "* Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movielens10M: Verifying data consistency...\n",
      "Movielens10M: Verifying data consistency... Passed!\n",
      "DataReader: current dataset is: Movielens10M\n",
      "\tNumber of items: 10681\n",
      "\tNumber of users: 69878\n",
      "\tNumber of interactions in URM_all: 10000054\n",
      "\tValue range in URM_all: 0.50-5.00\n",
      "\tInteraction density: 1.34E-02\n",
      "\tInteractions per user:\n",
      "\t\t Min: 2.00E+01\n",
      "\t\t Avg: 1.43E+02\n",
      "\t\t Max: 7.36E+03\n",
      "\tInteractions per item:\n",
      "\t\t Min: 0.00E+00\n",
      "\t\t Avg: 9.36E+02\n",
      "\t\t Max: 3.49E+04\n",
      "\tGini Index: 0.57\n",
      "\n",
      "\tICM name: ICM_all, Value range: 1.00 / 69.00, Num features: 10126, feature occurrences: 128384, density 1.19E-03\n",
      "\tICM name: ICM_genres, Value range: 1.00 / 1.00, Num features: 20, feature occurrences: 21564, density 1.01E-01\n",
      "\tICM name: ICM_tags, Value range: 1.00 / 69.00, Num features: 10106, feature occurrences: 106820, density 9.90E-04\n",
      "\tICM name: ICM_year, Value range: 6.00E+00 / 2.01E+03, Num features: 1, feature occurrences: 10681, density 1.00E+00\n",
      "\n",
      "\n",
      "Warning: 73 (0.10 %) of 69878 users have no sampled items\n"
     ]
    }
   ],
   "source": [
    "from Data_manager.split_functions.split_train_validation_random_holdout import split_train_in_two_percentage_global_sample\n",
    "from Data_manager.Movielens.Movielens10MReader import Movielens10MReader\n",
    "\n",
    "data_reader = Movielens10MReader()\n",
    "data_loaded = data_reader.load_data()\n",
    "\n",
    "URM_all = data_loaded.get_URM_all()\n",
    "\n",
    "URM_train, URM_test = split_train_in_two_percentage_global_sample(URM_all, train_percentage = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MF models rely upon latent factors for users and items which are called 'embeddings'\n",
    "\n",
    "![latent factors](https://miro.medium.com/max/988/1*tiF4e4Y-wVH732_6TbJVmQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "n_users, n_items = URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Creates U\n",
    "user_factors = torch.nn.Embedding(num_embeddings=n_users, embedding_dim=num_factors)\n",
    "\n",
    "# Creates V\n",
    "item_factors = torch.nn.Embedding(num_embeddings=n_items, embedding_dim=num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(69878, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(10681, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In order to compute the prediction you have to:\n",
    "- Get a list of user and item indices (as tensors)\n",
    "- Get the user and item embedding\n",
    "- Compute the element-wise product of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([42]), tensor([42]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_index = torch.Tensor([42]).type(torch.LongTensor)\n",
    "item_index = torch.Tensor([42]).type(torch.LongTensor)\n",
    "\n",
    "user_index, item_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notice that each object has a \"grad_fn=...\" attribute, which si going to be used for the automatic gradient compuation to go backwards in the operations required to compute the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2612, -0.3543, -0.6551, -0.2665,  1.3873,  0.9087, -1.1422, -1.0704,\n",
       "          -0.9945, -0.3808]], grad_fn=<EmbeddingBackward0>),\n",
       " tensor([[-0.3022, -0.1802, -1.6826, -1.7238,  0.2321, -1.2349,  0.1888, -1.1565,\n",
       "          -0.2198, -0.0691]], grad_fn=<EmbeddingBackward0>))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_user_factors = user_factors(user_index)\n",
    "current_item_factors = item_factors(item_index)\n",
    "\n",
    "current_user_factors, current_item_factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dot product is just a summation over the elementwise product. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.1714, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = torch.mul(current_user_factors, current_item_factors).sum()\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the \"grad_fn\" states \"SubBackward\", the prediction was indeed due to a sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To take the result of the prediction and transform it into a traditional numpy array you have to:\n",
    "- call .detach() to disconnect the tensor from the automatic gradient tracking\n",
    "- then .numpy()\n",
    "\n",
    "### The result is an array of 1 cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 2.17\n"
     ]
    }
   ],
   "source": [
    "prediction_numpy = prediction.detach().numpy()\n",
    "print(\"Prediction is {:.2f}\".format(prediction_numpy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a MF MSE model with PyTorch\n",
    "\n",
    "# Step 1 Create a Model python object\n",
    "\n",
    "### The model should implement the forward function which computes the prediction as we did before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF_MSE_PyTorch_model(torch.nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_factors):\n",
    "        super(MF_MSE_PyTorch_model, self).__init__()\n",
    "\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "\n",
    "        self.user_factors = torch.nn.Embedding(num_embeddings=self.n_users, embedding_dim=n_factors)\n",
    "        self.item_factors = torch.nn.Embedding(num_embeddings=self.n_items, embedding_dim=n_factors)\n",
    "\n",
    "    def forward(self, user_batch, item_batch):\n",
    "        user_factors_batch = self.user_factors(user_batch)\n",
    "        item_factors_batch = self.item_factors(item_batch)\n",
    "\n",
    "        prediction_batch = torch.mul(user_factors_batch, item_factors_batch).sum()\n",
    "\n",
    "        return prediction_batch\n",
    "\n",
    "    def get_W(self):\n",
    "        return self.user_factors.weight.detach().cpu().numpy()\n",
    "\n",
    "    def get_H(self):\n",
    "        return self.item_factors.weight.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Setup PyTorch devices and Data Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_MSE_PyTorch: Using CPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"MF_MSE_PyTorch: Using CUDA\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"MF_MSE_PyTorch: Using CPU\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance of the model and specify the device it should run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MF_MSE_PyTorch_model(n_users, n_items, num_factors).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose loss functions (Mean Squared Error in our case), there are quite a few to choose from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossFunction = torch.nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "# Alternatively one can implement it \n",
    "# # Compute prediction for each element in batch\n",
    "# prediction = model.forward(user, item)\n",
    "\n",
    "# # Compute total loss for batch\n",
    "# loss = (prediction - rating).pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the optimizer to be used for the model parameters: Adam, AdaGrad, RMSProp etc... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "l2_reg = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adagrad(pyTorchModel.parameters(), lr=learning_rate, weight_decay = l2_reg*learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the DatasetInteraction, which will be used to load a specific data point\n",
    "\n",
    "A DatasetInteraction will implement the Dataset class and provide the \\_\\_getitem\\_\\_(self, index) method, which allows to get the data points indexed by that index.\n",
    "\n",
    "Since we need the data to be a tensor, we pre inizialize everything as a tensor. In practice we save the URM in coordinate format (user, item, rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class DatasetInteraction(Dataset):\n",
    "    def __init__(self, URM):\n",
    "\n",
    "        URM = URM.tocoo()\n",
    "        self.n_data_points = URM.nnz\n",
    "\n",
    "        self._row = torch.tensor(URM.row).type(torch.LongTensor)\n",
    "        self._col = torch.tensor(URM.col).type(torch.LongTensor)\n",
    "        self._data = torch.tensor(URM.data).type(torch.FloatTensor)\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        return self._row[index], self._col[index], self._data[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We pass the DatasetIterator to a DataLoader object which manages the use of batches and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "dataset_iterator = DatasetInteraction(URM_train)\n",
    "\n",
    "train_data_loader = DataLoader(dataset=dataset_iterator,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               #num_workers = 2,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now we ran the usual epoch steps\n",
    "* Data point sampling\n",
    "* Prediction computation\n",
    "* Loss function computation\n",
    "* Gradient computation\n",
    "* Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([55877, 19312, 24075, 19060, 64707, 41696, 56003, 10467, 66007, 16603,\n",
       "         12450, 67142, 10662, 21143, 14825, 38048, 18833, 63230, 13473, 31861,\n",
       "         37967, 67829, 59446,  7420, 30722, 31862, 34228, 24813, 19334, 28065,\n",
       "         28738, 23852, 64311, 63451, 16034, 15889, 23528, 56756,  1248, 35262,\n",
       "         43425, 13122,   329, 60618, 23507,  4079, 13309,  7012, 58301,  9603,\n",
       "         29972, 65868,  5171, 58973, 27035, 31337,  7495,   898, 65087, 18354,\n",
       "         13144, 40990, 50012, 28106, 33860, 31512,  1218, 29815,  4371, 30722,\n",
       "         33884, 38734,  3803, 24856, 40491,  5663,  5286,  2595, 21149, 41367,\n",
       "         42994, 20021, 29436, 31324, 11245, 22654, 41428, 31546, 34722, 21823,\n",
       "         51990,  4325, 33777, 23290, 18357, 50828, 49908,  6355, 22975, 63019,\n",
       "         35932, 33492, 60093, 56595, 28502, 16118, 46764, 37908,  1006, 46527,\n",
       "         65426, 30994, 61017, 47505, 39592, 57101,  1643, 65732, 39445, 12371,\n",
       "         31587, 61256, 17150, 37275, 51294, 55286, 12754, 48633, 22333, 23710,\n",
       "         19569, 60479, 55072, 19875, 67546, 53536, 62748, 43238,  5939, 57329,\n",
       "         32106, 57035, 30610, 33611, 22950, 23037, 30604,  1774,   103, 14889,\n",
       "         31909, 46583, 21985,  9506, 57635, 62627, 65278, 64435, 57513, 58197,\n",
       "         38818,   367, 68107, 22497, 60636,  8013, 29693, 64437, 69587, 13375,\n",
       "         29527, 69864, 55008, 22218, 47021, 48846, 44054, 19536, 17277, 69467,\n",
       "         11041, 59134, 64574, 25454,  7849, 22205,  1632, 60804, 12811, 24668,\n",
       "         33463, 62471, 55654, 26058, 21201, 28350, 33786, 46970,  6954, 43798]),\n",
       " tensor([  34,  775, 2765, 2404, 5954,  599, 1211, 4716, 2888,  160, 1425,  228,\n",
       "         3095, 2114, 1348,  213, 1008, 1881,  192, 1864,  271, 1481,  324, 1293,\n",
       "          491,   27, 1171,  331, 3076,  161, 2099, 4564,  540,   14, 1964,  611,\n",
       "         2027, 3154, 1873, 1655, 3003, 1983, 1879, 1230,  678, 1023, 2895,   95,\n",
       "           83,  466,  474, 5660, 2841,  556, 1257,   81, 2018,  481,  141, 3181,\n",
       "         4283,   31, 3159,  373,   84,  798,  337, 4700, 1617, 2011,  949, 1698,\n",
       "          101,  628, 4508, 1351,  556, 2562,  162,  505, 1963, 5764,  391,  321,\n",
       "         1872, 3456, 1460, 2056,   60,  308, 6007,   88, 1478,  408,   94,  973,\n",
       "          130, 2998,  572, 2526, 3811,    9, 1418,  716, 4390,   31, 2197,  429,\n",
       "           85,  965, 2003, 2350, 1692,  461,  746,  179, 2671,  691, 1484, 4313,\n",
       "          174,  354,  292,  285, 2683,  123,  545, 2612, 1822, 1339,  260, 1878,\n",
       "          725, 3918, 1183,   23, 1153,  403, 2681,  707,  566, 1538,  202, 1317,\n",
       "         2969, 2340,    4,  660,  438, 2048, 2542,   18, 1054, 5155,  720,  201,\n",
       "         3096, 2715, 2003,   76,  487, 1351,  625,  213, 1005,   98,   22, 1458,\n",
       "         2582, 2731,  692,  540,  142,  241, 1280, 2746,  913, 1272,   24,  687,\n",
       "          441, 6997,  245, 1524,  123,  435, 1920,  530, 1281,  107,   43, 1344,\n",
       "          401,   10, 6681, 1460,  242,    7,  543,  533]),\n",
       " tensor([3.0000, 3.0000, 5.0000, 4.5000, 1.0000, 3.0000, 4.0000, 3.0000, 2.0000,\n",
       "         5.0000, 4.0000, 4.0000, 4.0000, 5.0000, 3.0000, 4.0000, 3.0000, 2.0000,\n",
       "         3.0000, 3.5000, 0.5000, 2.0000, 4.0000, 3.0000, 1.0000, 3.0000, 3.0000,\n",
       "         4.0000, 1.0000, 5.0000, 3.0000, 3.0000, 4.0000, 3.0000, 5.0000, 2.0000,\n",
       "         2.0000, 2.0000, 3.0000, 4.0000, 3.0000, 4.0000, 4.0000, 3.5000, 5.0000,\n",
       "         4.0000, 3.5000, 4.0000, 3.0000, 4.5000, 1.0000, 3.0000, 4.5000, 5.0000,\n",
       "         3.0000, 4.0000, 5.0000, 4.0000, 2.0000, 3.0000, 0.5000, 3.5000, 5.0000,\n",
       "         4.0000, 4.0000, 1.0000, 2.0000, 4.5000, 2.0000, 3.0000, 3.5000, 1.0000,\n",
       "         4.0000, 3.0000, 4.0000, 3.0000, 3.0000, 2.0000, 3.5000, 4.0000, 1.0000,\n",
       "         3.0000, 5.0000, 2.0000, 4.0000, 1.0000, 3.0000, 4.0000, 3.5000, 1.0000,\n",
       "         4.0000, 4.0000, 3.0000, 3.5000, 4.5000, 4.0000, 5.0000, 3.0000, 3.5000,\n",
       "         4.0000, 3.5000, 2.0000, 5.0000, 3.0000, 3.5000, 3.0000, 5.0000, 3.5000,\n",
       "         3.0000, 3.0000, 5.0000, 4.0000, 3.0000, 3.0000, 3.5000, 4.0000, 4.0000,\n",
       "         3.0000, 4.0000, 1.0000, 4.0000, 1.0000, 3.5000, 4.0000, 3.5000, 4.0000,\n",
       "         4.0000, 2.0000, 4.0000, 2.0000, 4.0000, 2.5000, 3.0000, 4.0000, 4.5000,\n",
       "         3.0000, 5.0000, 2.5000, 4.0000, 1.0000, 5.0000, 3.0000, 2.0000, 4.0000,\n",
       "         5.0000, 4.0000, 3.0000, 4.0000, 3.0000, 4.0000, 3.0000, 4.0000, 4.5000,\n",
       "         5.0000, 1.0000, 4.5000, 2.0000, 3.5000, 5.0000, 4.0000, 4.0000, 4.0000,\n",
       "         5.0000, 3.5000, 4.0000, 5.0000, 5.0000, 4.0000, 0.5000, 4.0000, 3.5000,\n",
       "         4.0000, 3.0000, 4.0000, 4.5000, 5.0000, 3.0000, 3.0000, 4.0000, 4.0000,\n",
       "         3.0000, 4.0000, 4.5000, 4.0000, 3.5000, 5.0000, 2.0000, 4.0000, 5.0000,\n",
       "         5.0000, 5.0000, 4.0000, 4.0000, 3.0000, 4.0000, 4.0000, 3.5000, 4.0000,\n",
       "         3.0000, 2.0000])]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_data_loader))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c773f2177ba1495ba57bff456b106c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "epoch_loss = 0\n",
    "for batch in tqdm(train_data_loader):\n",
    "\n",
    "    # Clear previously computed gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    user, item, rating = batch\n",
    "    \n",
    "    # Compute prediction for each element in batch\n",
    "    prediction = model.forward(user, item)\n",
    "    \n",
    "    # Compute total loss for batch\n",
    "    loss = (prediction - rating).pow(2).mean()\n",
    "\n",
    "    # Compute gradients given current loss\n",
    "    loss.backward()\n",
    "\n",
    "    # Apply gradient using the selected optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    epoch_loss += loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After the train is complete (it may take a while and many epochs), we can get the matrices in the usual numpy format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = model.get_W()\n",
    "item_factors = model.get_H()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.24113546,  0.47087878, -0.37134743, ..., -0.07847775,\n",
       "          0.4398791 , -1.1129218 ],\n",
       "        [ 1.4219416 , -0.3765659 , -1.3486185 , ...,  0.3462894 ,\n",
       "         -1.8700924 ,  1.1192238 ],\n",
       "        [-1.6435713 , -0.5942621 , -0.58973074, ..., -0.5677242 ,\n",
       "          0.622611  , -0.04073808],\n",
       "        ...,\n",
       "        [-0.10797215, -0.15036593, -0.73183084, ...,  1.0499629 ,\n",
       "          0.38393408, -0.5881524 ],\n",
       "        [-2.4141316 , -0.5980451 ,  0.79490495, ...,  0.41315082,\n",
       "          0.45508152,  1.2279824 ],\n",
       "        [-0.22037579,  0.32465494, -0.036454  , ...,  1.3806891 ,\n",
       "          1.6919811 , -0.7237116 ]], dtype=float32),\n",
       " (69878, 10))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors, user_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.2975809 ,  0.1412901 ,  1.335745  , ..., -0.9085001 ,\n",
       "         -0.9057294 ,  2.647488  ],\n",
       "        [-0.03020126, -1.4139888 , -0.53759825, ..., -0.670331  ,\n",
       "         -1.1529027 ,  0.33455744],\n",
       "        [-0.8532554 ,  1.160232  , -1.198196  , ..., -0.28911358,\n",
       "          0.77140486,  1.1398466 ],\n",
       "        ...,\n",
       "        [ 0.14160302,  0.212637  ,  1.6776506 , ..., -1.1952226 ,\n",
       "         -0.31479314,  0.12797183],\n",
       "        [-2.0611856 , -1.3277111 ,  1.1998678 , ...,  0.93477297,\n",
       "          1.291561  , -0.00728516],\n",
       "        [ 0.017063  ,  0.12725203, -0.40303975, ...,  0.37394723,\n",
       "          0.3055245 , -0.03744027]], dtype=float32),\n",
       " (10681, 10))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors, item_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to change the sampling?\n",
    "The DatasetInteraction can be modified to obtain the desired behaviour, for example adding some negative (zero-rated) items in the sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class DatasetInteraction(Dataset):\n",
    "    def __init__(self, URM_train, positive_quota):\n",
    "        \n",
    "        self._URM_train = sps.csr_matrix(URM_train)\n",
    "        \n",
    "        URM_train = URM_train.tocoo()\n",
    "        self.n_data_points = URM.nnz\n",
    "\n",
    "        self._row = torch.tensor(URM_train.row).type(torch.LongTensor)\n",
    "        self._col = torch.tensor(URM_train.col).type(torch.LongTensor)\n",
    "        self._data = torch.tensor(URM_train.data).type(torch.FloatTensor)\n",
    "        self._positive_quota = positive_quota\n",
    "       \n",
    "    def __getitem__(self, index):\n",
    "        select_positive_flag = torch.rand(1, requires_grad=False) > self._positive_quota\n",
    "\n",
    "        if select_positive_flag[0]:\n",
    "            return self._row[index], self._col[index], self._data[index]\n",
    "        else:\n",
    "            user_id = self._row[index]\n",
    "            seen_items = self._URM_train.indices[self._URM_train.indptr[user_id]:self._URM_train.indptr[user_id+1]]\n",
    "            negative_selected = False\n",
    "\n",
    "            while not negative_selected:\n",
    "                negative_candidate = torch.randint(low=0, high=self.n_items, size=(1,))[0]\n",
    "\n",
    "                if negative_candidate not in seen_items:\n",
    "                    item_negative = negative_candidate\n",
    "                    negative_selected = True\n",
    "\n",
    "            return self._row[index], item_negative, torch.tensor(0.0)\n",
    "\n",
    "        \n",
    "        return self._row[index], self._col[index], self._data[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_data_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to implement AsySVD? SLIM EN ... \n",
    "You just have to change the pytorch model with the desired one (easy to do)\n",
    "\n",
    "You may want to change the dataset iterator to one that samples the user profile rather than the specific interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserProfile_Dataset(Dataset):\n",
    "    def __init__(self, URM_train, device):\n",
    "        super().__init__()\n",
    "        URM_train = sps.csr_matrix(URM_train)\n",
    "        self.device = device\n",
    "\n",
    "        self.n_users, self.n_items = URM_train.shape\n",
    "        self._indptr = URM_train.indptr\n",
    "        self._indices = torch.tensor(URM_train.indices, dtype = torch.long, device=device)\n",
    "        self._data = torch.tensor(URM_train.data, dtype = torch.float, device=device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_users\n",
    "\n",
    "    def __getitem__(self, user_id):\n",
    "        start_pos = self._indptr[user_id]\n",
    "        end_pos = self._indptr[user_id+1]\n",
    "\n",
    "        user_profile = torch.zeros(self.n_items, dtype=torch.float, requires_grad=False, device=self.device)\n",
    "        user_profile[self._indices[start_pos:end_pos]] = self._data[start_pos:end_pos]\n",
    "\n",
    "        return user_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class AsySVDModel(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_size = None, n_items = None, device = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self._embedding_item_1 = torch.nn.Parameter(torch.randn((n_items, embedding_size)))\n",
    "        self._embedding_item_2 = torch.nn.Parameter(torch.randn((embedding_size, n_items)))\n",
    "\n",
    "    def forward(self, user_profile_batch):\n",
    "        # input shape is batch_size x n items\n",
    "        # r_hat_bi = SUM{e=0}{e=embedding_size} SUM{j=0}{j=n items} r_bj * V1_je * V2_ei\n",
    "        layer_output = torch.einsum(\"bj,je,ei->bi\", user_profile_batch, self._embedding_item_1, self._embedding_item_2)\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDenseModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_items = None, device = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self._S = torch.nn.Parameter(torch.zeros((n_items, n_items)))\n",
    "\n",
    "    def forward(self, user_profile_batch):\n",
    "        # R = R*V*V.t\n",
    "        layer_output = torch.einsum(\"bi,ik->bk\", user_profile_batch, self._S)\n",
    "        return layer_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I want to change the loss function?\n",
    "You can just implement the new one, BPR is quite simple. Make sure that the dataset iterator samples the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPR_Dataset(Dataset):\n",
    "    def __init__(self, URM_train):\n",
    "        super().__init__()\n",
    "        self._URM_train = sps.csr_matrix(URM_train)\n",
    "        self.n_users, self.n_items = self._URM_train.shape\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_users\n",
    "\n",
    "    def __getitem__(self, user_id):\n",
    "\n",
    "        seen_items = self._URM_train.indices[self._URM_train.indptr[user_id]:self._URM_train.indptr[user_id+1]]\n",
    "        item_positive = np.random.choice(seen_items)\n",
    "\n",
    "        negative_selected = False\n",
    "\n",
    "        while not negative_selected:\n",
    "            negative_candidate = np.random.randint(low=0, high=self.n_items, size=1)[0]\n",
    "\n",
    "            if negative_candidate not in seen_items:\n",
    "                item_negative = negative_candidate\n",
    "                negative_selected = True\n",
    "\n",
    "        return user_id, item_positive, item_negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_BPR(model, batch):\n",
    "    user, item_positive, item_negative = batch\n",
    "\n",
    "    # Compute prediction for each element in batch\n",
    "    x_ij = model.forward(user, item_positive) - model.forward(user, item_negative)\n",
    "\n",
    "    # Compute total loss for batch\n",
    "    loss = -x_ij.sigmoid().log().mean()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
