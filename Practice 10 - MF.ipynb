{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems 2020/21\n",
    "\n",
    "## Practice session on MF recommenders.\n",
    "\n",
    "### Outline\n",
    "* MF Recommenders\n",
    "* BPR-MF\n",
    "* PureSVD\n",
    "* Comparison of MF recommenders\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Administrative code\n",
    "\n",
    "download the dataset and generate _TRAIN_ and _TEST_ splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "import zipfile, os\n",
    "\n",
    "# If file exists, skip the download\n",
    "data_file_path = \"data/Movielens_10M/\"\n",
    "data_file_name = data_file_path + \"movielens_10m.zip\"\n",
    "\n",
    "# If directory does not exist, create\n",
    "if not os.path.exists(data_file_path):\n",
    "    os.makedirs(data_file_path)\n",
    "\n",
    "if not os.path.exists(data_file_name):\n",
    "    urlretrieve (\"http://files.grouplens.org/datasets/movielens/ml-10m.zip\", data_file_name)\n",
    "    \n",
    "dataFile = zipfile.ZipFile(data_file_name)\n",
    "URM_path = dataFile.extract(\"ml-10M100K/ratings.dat\", path=\"data/Movielens_10M\")\n",
    "URM_file = open(URM_path, 'r')\n",
    "\n",
    "\n",
    "def rowSplit (rowString):\n",
    "    \n",
    "    split = rowString.split(\"::\")\n",
    "    split[3] = split[3].replace(\"\\n\",\"\")\n",
    "    \n",
    "    split[0] = int(split[0])\n",
    "    split[1] = int(split[1])\n",
    "    split[2] = float(split[2])\n",
    "    split[3] = int(split[3])\n",
    "    \n",
    "    result = tuple(split)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "URM_file.seek(0)\n",
    "URM_tuples = []\n",
    "\n",
    "for line in URM_file:\n",
    "   URM_tuples.append(rowSplit (line))\n",
    "\n",
    "userList, itemList, ratingList, timestampList = zip(*URM_tuples)\n",
    "\n",
    "userList = list(userList)\n",
    "itemList = list(itemList)\n",
    "ratingList = list(ratingList)\n",
    "timestampList = list(timestampList)\n",
    "\n",
    "import scipy.sparse as sps\n",
    "\n",
    "URM_all = sps.coo_matrix((ratingList, (userList, itemList)))\n",
    "URM_all = URM_all.tocsr()\n",
    "\n",
    "from Notebooks_utils.data_splitter import train_test_holdout\n",
    "\n",
    "URM_train, URM_test = train_test_holdout(URM_all, train_perc = 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF Computing prediction\n",
    "\n",
    "In a MF model you have two matrices, let's call them $W$ and $H$. \n",
    "\n",
    "In $W$ you have one row for every user (i.e., users are in the rows). In $H$ you have one column for every item (i.e., items are in the columns). The other dimension (columns for $W$ and rows for $H$) is called latent factors.\n",
    "\n",
    "The number of latent factors is variable (a hyperparameter), if we represent the number of item factors by $k$, then $W$ is an $m \\times k$ matrix and $H$ is an $k \\times n$ matrix. Lastly, $W$ is called the user factors matrix and $H$ is the item factors matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 10\n",
    "\n",
    "n_users, n_items = URM_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# user_factors is our W\n",
    "user_factors = np.random.random((n_users, num_factors))\n",
    "\n",
    "# item_factors is our H\n",
    "item_factors = np.random.random((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.30634973, 0.0334021 , 0.25344635, ..., 0.03832807, 0.36253854,\n",
       "         0.6852888 ],\n",
       "        [0.97605076, 0.69946001, 0.24327959, ..., 0.6639383 , 0.40079897,\n",
       "         0.97580331],\n",
       "        [0.34375125, 0.84824167, 0.90709905, ..., 0.33146097, 0.9627483 ,\n",
       "         0.63718458],\n",
       "        ...,\n",
       "        [0.53322894, 0.96085398, 0.81110603, ..., 0.30456711, 0.69836226,\n",
       "         0.37155581],\n",
       "        [0.86971444, 0.4972253 , 0.61423456, ..., 0.4391501 , 0.71144387,\n",
       "         0.97102994],\n",
       "        [0.25394936, 0.90668942, 0.79459965, ..., 0.91325561, 0.72095031,\n",
       "         0.69359958]]),\n",
       " (71568, 10))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors, user_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.06328835, 0.72899745, 0.03065499, ..., 0.20469492, 0.89902618,\n",
       "         0.06134449],\n",
       "        [0.00272137, 0.75781835, 0.97385761, ..., 0.26666058, 0.32539796,\n",
       "         0.69209126],\n",
       "        [0.81389969, 0.5323244 , 0.08558432, ..., 0.25887259, 0.02654925,\n",
       "         0.25694279],\n",
       "        ...,\n",
       "        [0.05582767, 0.73427087, 0.35413686, ..., 0.3132589 , 0.81055021,\n",
       "         0.77698438],\n",
       "        [0.67892742, 0.26486257, 0.00115278, ..., 0.0639313 , 0.00733244,\n",
       "         0.39480394],\n",
       "        [0.18804592, 0.85048359, 0.29146487, ..., 0.10601249, 0.06888341,\n",
       "         0.16657638]]),\n",
       " (65134, 10))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors, item_factors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the prediction we have to muliply the user factors to the item factors\n",
    "\n",
    "$$\\hat{x}_{ui} = \\langle w_u,h_i \\rangle = \\sum_{f=1}^k w_{uf} \\cdot h_{if}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's suppose Bob is user 42.\n",
    "\n",
    "![Bob](./images/bob_example.jpeg)\n",
    "\n",
    "And that we're interested into the movie Toy Story (with id 15).\n",
    "\n",
    "![Toy Story](./images/toy_story_poster.png)\n",
    "\n",
    "In our specific case, let's see what is the rating for user $u = 42$ and item $i = 15$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 0 with size 10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-133-8d0128a13eba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0muser_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m42\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muser_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem_factors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction is {:.2f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 15 is out of bounds for axis 0 with size 10"
     ]
    }
   ],
   "source": [
    "item_index = 15\n",
    "user_index = 42\n",
    "\n",
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a MF MSE model\n",
    "\n",
    "### Use SGD as we saw for SLIM\n",
    "\n",
    "Keeping the same idea for $u = 42$ and $i = 15$, let's suppose that the real rating $r_{u,i} = 5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Prediction error is 2.10\n",
      "* Real value (r_u,i) is 5\n",
      "* Prediction (rhat_u,i) is 2.9007965242616613\n"
     ]
    }
   ],
   "source": [
    "test_data = 5\n",
    "\n",
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "gradient = test_data - prediction\n",
    "\n",
    "print(f\"* Prediction error is {gradient:.2f}\")\n",
    "print(f\"* Real value (r_u,i) is {test_data}\")\n",
    "print(f\"* Prediction (rhat_u,i) is {prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, for SGD we have a regularization parameter $\\lambda_\\Theta$ and the learning rate hyperparameter $lr$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "regularization = 1e-3\n",
    "\n",
    "# Copy original value to avoid messing up the updates\n",
    "H_i = item_factors[item_index,:]\n",
    "W_u = user_factors[user_index,:]\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (gradient * H_i - regularization * W_u)\n",
    "item_factors[item_index,:] += learning_rate * (gradient * W_u - regularization * H_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we updated the user and item factors, let's see the new prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Prediction error is 1.96\n",
      "* Real value (r_u,i) is 5\n",
      "* Prediction (rhat_u,i) is 3.0440809587341278\n"
     ]
    }
   ],
   "source": [
    "new_prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "new_gradient = test_data - new_prediction\n",
    "\n",
    "print(f\"* Prediction error is {new_gradient:.2f}\")\n",
    "print(f\"* Real value (r_u,i) is {test_data}\")\n",
    "print(f\"* Prediction (rhat_u,i) is {new_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\t\t\t|Previous Values \t|After Gradient values\n",
      "___________________________________________________________________________\n",
      "Prediction Error\t|2.10\t\t\t|1.96\n",
      "Real value (r_u,i)\t|5\t\t\t|5\n",
      "Prediction (rhat_u,i)\t|2.90\t\t\t|3.04\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature\\t\\t\\t|Previous Values \\t|After Gradient values\")\n",
    "print(f\"___________________________________________________________________________\")\n",
    "print(f\"Prediction Error\\t|{gradient:.2f}\\t\\t\\t|{new_gradient:.2f}\")\n",
    "print(f\"Real value (r_u,i)\\t|{test_data}\\t\\t\\t|{test_data}\")\n",
    "print(f\"Prediction (rhat_u,i)\\t|{prediction:.2f}\\t\\t\\t|{new_prediction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⚠️WARNING: Initialization must be done with random non-zero values⚠️\n",
    "\n",
    "... otherwise this happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = np.zeros((n_users, num_factors))\n",
    "item_factors = np.zeros((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Prediction error is 5.00\n",
      "* Real value (r_u,i) is 5\n",
      "* Prediction (rhat_u,i) is 0.0\n"
     ]
    }
   ],
   "source": [
    "prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "gradient = test_data - prediction\n",
    "\n",
    "print(f\"* Prediction error is {gradient:.2f}\")\n",
    "print(f\"* Real value (r_u,i) is {test_data}\")\n",
    "print(f\"* Prediction (rhat_u,i) is {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_u = user_factors[user_index,:]\n",
    "H_i = item_factors[item_index,:]\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (gradient * H_i - regularization * W_u)\n",
    "item_factors[item_index,:] += learning_rate * (gradient * W_u - regularization * H_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Prediction error is 5.00\n",
      "* Real value (r_u,i) is 5\n",
      "* Prediction (rhat_u,i) is 0.0\n"
     ]
    }
   ],
   "source": [
    "new_prediction = np.dot(user_factors[user_index,:], item_factors[item_index,:])\n",
    "new_gradient = test_data - new_prediction\n",
    "\n",
    "print(f\"* Prediction error is {new_gradient:.2f}\")\n",
    "print(f\"* Real value (r_u,i) is {test_data}\")\n",
    "print(f\"* Prediction (rhat_u,i) is {new_prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the updates multiply the gradient and the latent factors, if those are zero the SGD will never be able to move from that point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MF BPR models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap on BPR\n",
    "S.Rendle et al. BPR: Bayesian Personalized Ranking from Implicit Feedback. UAI2009\n",
    "\n",
    "The usual approach for item recommenders is to predict a personalized score $\\hat{x}_{ui}$ for an item that reflects the preference of the user for the item. Then the items are ranked by sorting them according to that score.\n",
    "\n",
    "Machine learning approaches are tipically fit by using observed items as a positive sample and missing ones for the negative class. A perfect model would thus be useless, as it would classify as negative (non-interesting) all the items that were non-observed at training time. The only reason why such methods work is regularization.\n",
    "\n",
    "BPR use a different approach. The training dataset is composed by triplets $(u,i,j)$ representing that user u is assumed to prefer i over j. For an implicit dataset this means that u observed i but not j:\n",
    "$$D_S := \\{(u,i,j) \\mid i \\in I_u^+ \\wedge j \\in I \\setminus I_u^+\\}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR-OPT\n",
    "A machine learning model can be represented by a parameter vector $\\Theta$ which is found at fitting time. BPR wants to find the parameter vector that is most probable given the desired, but latent, preference structure $>_u$:\n",
    "$$p(\\Theta \\mid >_u) \\propto p(>_u \\mid \\Theta)p(\\Theta) $$\n",
    "$$\\prod_{u\\in U} p(>_u \\mid \\Theta) = \\dots = \\prod_{(u,i,j) \\in D_S} p(i >_u j \\mid \\Theta) $$\n",
    "\n",
    "The probability that a user really prefers item $i$ to item $j$ is defined as:\n",
    "$$ p(i >_u j \\mid \\Theta) := \\sigma(\\hat{x}_{uij}(\\Theta)) $$\n",
    "Where $\\sigma$ represent the logistic sigmoid and $\\hat{x}_{uij}(\\Theta)$ is an arbitrary real-valued function of $\\Theta$ (the output of your arbitrary model).\n",
    "\n",
    "\n",
    "To complete the Bayesian setting, we define a prior density for the parameters:\n",
    "$$p(\\Theta) \\sim N(0, \\Sigma_\\Theta)$$\n",
    "And we can now formulate the maximum posterior estimator:\n",
    "$$BPR-OPT := \\log p(\\Theta \\mid >_u) $$\n",
    "$$ = \\log p(>_u \\mid \\Theta) p(\\Theta) $$\n",
    "$$ = \\log \\prod_{(u,i,j) \\in D_S} \\sigma(\\hat{x}_{uij})p(\\Theta) $$\n",
    "$$ = \\sum_{(u,i,j) \\in D_S} \\log \\sigma(\\hat{x}_{uij}) + \\log p(\\Theta) $$\n",
    "$$ = \\sum_{(u,i,j) \\in D_S} \\log \\sigma(\\hat{x}_{uij}) - \\lambda_\\Theta ||\\Theta||^2 $$\n",
    "\n",
    "Where $\\lambda_\\Theta$ are model specific regularization parameters.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR learning algorithm\n",
    "Once obtained the log-likelihood, we need to maximize it in order to find our obtimal $\\Theta$. As the crierion is differentiable, gradient descent algorithms are an obvious choiche for maximization.\n",
    "\n",
    "Gradient descent comes in many fashions, you can find an overview on my master thesis https://www.politesi.polimi.it/bitstream/10589/133864/3/tesi.pdf on pages 18-19-20 (I'm linking my thesis just because I'm sure of what it's written there, many posts you can find online contain some error). A nice post about momentum is available here https://distill.pub/2017/momentum/\n",
    "\n",
    "The basic version of gradient descent consists in evaluating the gradient using all the available samples and then perform a single update. The problem with this is, in our case, that our training dataset is very skewed. Suppose an item $i$ is very popular. Then we have many terms of the form $\\hat{x}_{uij}$ in the loss because for many users u the item $i$ is compared against all negative items $j$.\n",
    "\n",
    "The other popular approach is stochastic gradient descent, where for each training sample an update is performed. This is a better approach, but the order in which the samples are traversed is crucial. To solve this issue BPR uses a stochastic gradient descent algorithm that choses the triples randomly.\n",
    "\n",
    "The gradient of BPR-OPT with respect to the model parameters is: \n",
    "$$\\frac{\\partial BPR-OPT}{\\partial \\Theta} = \\sum_{(u,i,j) \\in D_S} \\frac{\\partial}{\\partial \\Theta} \\log \\sigma (\\hat{x}_{uij}) - \\lambda_\\Theta \\frac{\\partial}{\\partial\\Theta} || \\Theta ||^2$$\n",
    "$$ =  \\sum_{(u,i,j) \\in D_S} \\frac{-e^{-\\hat{x}_{uij}}}{1+e^{-\\hat{x}_{uij}}} \\frac{\\partial}{\\partial \\Theta}\\hat{x}_{uij} - \\lambda_\\Theta \\Theta $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPR-MF\n",
    "\n",
    "In order to practically apply this learning schema to an existing algorithm, we first split the real valued preference term: $\\hat{x}_{uij} := \\hat{x}_{ui} − \\hat{x}_{uj}$. And now we can apply any standard collaborative filtering model that predicts $\\hat{x}_{ui}$.\n",
    "\n",
    "The problem of predicting $\\hat{x}_{ui}$ can be seen as the task of estimating a matrix $X:U×I$. With matrix factorization the target matrix $X$ is approximated by the matrix product of two low-rank matrices $W:|U|\\times k$ and $H:|I|\\times k$:\n",
    "$$X := WH^t$$\n",
    "The prediction formula can also be written as:\n",
    "$$\\hat{x}_{ui} = \\langle w_u,h_i \\rangle = \\sum_{f=1}^k w_{uf} \\cdot h_{if}$$\n",
    "Besides the dot product ⟨⋅,⋅⟩, in general any kernel can be used.\n",
    "\n",
    "We can now specify the derivatives:\n",
    "$$ \\frac{\\partial}{\\partial \\theta} \\hat{x}_{uij} = \\begin{cases}\n",
    "(h_{if} - h_{jf}) \\text{ if } \\theta=w_{uf}, \\\\\n",
    "w_{uf} \\text{ if } \\theta = h_{if}, \\\\\n",
    "-w_{uf} \\text{ if } \\theta = h_{jf}, \\\\\n",
    "0 \\text{ else }\n",
    "\\end{cases} $$\n",
    "\n",
    "Which basically means: user $u$ prefer $i$ over $j$, let's do the following:\n",
    "- Increase the relevance (according to $u$) of features belonging to $i$ but not to $j$ and vice-versa\n",
    "- Increase the relevance of features assigned to $i$\n",
    "- Decrease the relevance of features assigned to $j$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "The basics are the same, except for how we compute the gradient, where we have to sample triplets $(u, i^+, i^-)$ instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71568, 69808)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URM_mask = URM_train.copy()\n",
    "URM_mask.data[URM_mask.data <= 3] = 0\n",
    "\n",
    "URM_mask.eliminate_zeros()\n",
    "\n",
    "# Extract users having at least one interaction to choose from\n",
    "eligibleUsers = []\n",
    "\n",
    "for user_id in range(n_users):\n",
    "    start_pos = URM_mask.indptr[user_id]\n",
    "    end_pos = URM_mask.indptr[user_id+1]\n",
    "\n",
    "    if len(URM_mask.indices[start_pos:end_pos]) > 0:\n",
    "        eligibleUsers.append(user_id)  \n",
    "        \n",
    "n_users, len(eligibleUsers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampleTriplet():\n",
    "    # By randomly selecting a user in this way we could end up \n",
    "    # with a user with no interactions\n",
    "    #user_id = np.random.randint(0, n_users)\n",
    "    user_id = np.random.choice(eligibleUsers)\n",
    "    \n",
    "    # Get user seen items and choose one\n",
    "    userSeenItems = URM_mask[user_id,:].indices\n",
    "    pos_item_id = np.random.choice(userSeenItems)\n",
    "\n",
    "    negItemSelected = False\n",
    "\n",
    "    # It's faster to just try again than to build a mapping of the non-seen items\n",
    "    while (not negItemSelected):\n",
    "        neg_item_id = np.random.randint(0, n_items)\n",
    "\n",
    "        if (neg_item_id not in userSeenItems):\n",
    "            negItemSelected = True\n",
    "\n",
    "    return user_id, pos_item_id, neg_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35367, 5662, 42849)\n",
      "(45465, 2968, 50288)\n",
      "(34633, 2340, 4700)\n",
      "(29730, 1203, 43251)\n",
      "(28437, 6662, 8483)\n",
      "(59469, 260, 15021)\n",
      "(50988, 1580, 2582)\n",
      "(58343, 780, 31875)\n",
      "(26245, 6016, 55625)\n",
      "(60326, 628, 16503)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(sampleTriplet())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_factors = np.random.random((n_users, num_factors))\n",
    "item_factors = np.random.random((n_items, num_factors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63015 2570 30439\n"
     ]
    }
   ],
   "source": [
    "user_id, positive_item, negative_item = sampleTriplet()\n",
    "\n",
    "print(user_id, positive_item, negative_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.28379899, 0.75008391, 0.18811677, 0.65365122, 0.23148049,\n",
       "        0.76857424, 0.50208452, 0.77211623, 0.96833879, 0.44262847]),\n",
       " array([0.52856959, 0.40104207, 0.97270787, 0.78881351, 0.72402019,\n",
       "        0.66005275, 0.39898422, 0.75230664, 0.21492863, 0.94439139]),\n",
       " array([0.41226916, 0.41523953, 0.79698537, 0.65348332, 0.49786004,\n",
       "        0.91635758, 0.24349472, 0.70931779, 0.56359568, 0.04490193]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[user_id, :], item_factors[positive_item,:], item_factors[negative_item,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17100719602456516"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_uij = np.dot(user_factors[user_id, :], (item_factors[positive_item,:] - item_factors[negative_item,:]))\n",
    "x_uij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4573520814363014"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigmoid_item = 1 / (1 + np.exp(x_uij))\n",
    "sigmoid_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When using BPR we have to update three components, the user factors and the item factors of both the positive and negative item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_i = item_factors[positive_item,:]\n",
    "H_j = item_factors[negative_item,:]\n",
    "W_u = user_factors[user_id,:]\n",
    "\n",
    "user_factors[user_index,:] += learning_rate * (sigmoid_item * ( H_i - H_j ) - regularization * W_u)\n",
    "item_factors[positive_item,:] += learning_rate * (sigmoid_item * ( W_u ) - regularization * H_i)\n",
    "item_factors[negative_item,:] += learning_rate * (sigmoid_item * (-W_u ) - regularization * H_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2051418563363841"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x_uij = np.dot(user_factors[user_id, :], (item_factors[positive_item,:] - item_factors[negative_item,:]))\n",
    "new_x_uij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature\t\t\t|Previous Values \t|After Gradient values\n",
      "___________________________________________________________________________\n",
      "X_uij\t\t\t|0.17101\t\t|0.20514\n"
     ]
    }
   ],
   "source": [
    "print(f\"Feature\\t\\t\\t|Previous Values \\t|After Gradient values\")\n",
    "print(f\"___________________________________________________________________________\")\n",
    "print(f\"X_uij\\t\\t\\t|{x_uij:.5f}\\t\\t|{new_x_uij:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to rank items with MF ?\n",
    "\n",
    "Compute the prediction for all items and rank them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5452615 , 1.85112335, 2.33986462, ..., 2.11123538, 2.40540478,\n",
       "       2.39739784])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores = np.dot(user_factors[user_index,:], item_factors.T)\n",
    "item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65134,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping, how to use it and when it is needed\n",
    "\n",
    "Problem, how many epochs? 5, 10, 150, 2487 ?\n",
    "\n",
    "We could try different values in increasing order: 5, 10, 15, 20, 25...\n",
    "\n",
    "### However, in this way we would train up to a point, test and then discard the model, to re-train it again up to that same point and then some more... not a good idea.\n",
    "\n",
    "### Early stopping! \n",
    "* Train the model up to a certain number of epochs, say 5\n",
    "* Compute the recommendation quality on the validation set\n",
    "* Train for other 5 epochs\n",
    "* Compute the recommendation quality on the validation set AND compare it with the previous one. If better, then we have another best model, if not, go ahead...\n",
    "* Repeat until you have either reached the max number of epoch you want to allow (e.g., 300) or a certain number of contiguous validation seps have not updated te best model\n",
    "\n",
    "### Advantages:\n",
    "* Easy to implement, we already have all that is required, a train function, a predictor function and an evaluator\n",
    "* MUCH faster than retraining everything from the beginning\n",
    "* Often allows to reach even better solutions\n",
    "\n",
    "### Challenges:\n",
    "* The evaluation step may be very slow compared to the time it takes to re-train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PureSVD model\n",
    "\n",
    "### As opposed to the previous ones, PureSVD relies on the SVD decomposition of the URM, which is an easily available function\n",
    "\n",
    "In our case, an SVD decomposition of the URM ($m \\times n$)is as follows\n",
    "\n",
    "$$ URM = U \\Sigma V^T $$\n",
    "\n",
    "Where $U$ is an orthogonal $m \\times m$ matrix, $\\Sigma$ is a rectangular diagonal matrix ($m \\times n$), and $V^T$ is an orthogonal $n \\times n$ matrix. \n",
    "\n",
    "However, calculating the SVD for the whole URM consumes lots of resources (time and memory), we can use a *truncated* version of SVD called *Truncated SVD*, the idea is similar to the original SVD, but instead of calculating an *exact* decomposition, we approximate URM:\n",
    "\n",
    "$$ \\widehat{URM} = U_{t} \\Sigma_{t} V^*_{t} $$\n",
    "\n",
    "Where $U_{t}$ is a $m \\times t$ matrix, $\\Sigma_{t}$ is a $t$ vector, and $V^*_{t}$ is a $t \\times n$ matrix. For this approximation, only the $t$ largest singular values are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "\n",
    "# Other SVDs are also available, like from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, Sigma, VT = randomized_svd(URM_train,\n",
    "                              n_components=num_factors,\n",
    "                              random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.47450141e-23,  2.17209326e-16,  1.19566656e-17, ...,\n",
       "          2.39545180e-16,  3.66410642e-16,  3.85187471e-16],\n",
       "        [ 7.72781750e-04, -3.24632579e-03, -7.10266756e-04, ...,\n",
       "         -1.21827989e-03, -1.35942114e-03,  9.70545580e-05],\n",
       "        [ 5.68586952e-04, -8.96717393e-04, -1.23776718e-04, ...,\n",
       "          3.79701736e-03,  1.52671851e-03,  8.23628100e-04],\n",
       "        ...,\n",
       "        [ 3.09999454e-03,  2.26394683e-03,  6.37531943e-03, ...,\n",
       "          5.45681761e-04,  4.68820034e-04,  2.24664264e-03],\n",
       "        [ 1.35984951e-03, -4.71544070e-03,  1.25373531e-03, ...,\n",
       "          1.76627978e-03, -2.26022331e-03,  2.12474479e-03],\n",
       "        [ 1.07090876e-03, -6.13922117e-04, -3.70768123e-04, ...,\n",
       "          1.48700172e-03,  3.35459331e-04,  2.57856976e-03]]),\n",
       " (71568, 10))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U, U.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4274.92595946, 1783.56768962, 1532.10468684, 1226.25146812,\n",
       "        1184.15962709, 1013.86678896,  962.0184544 ,  908.57154466,\n",
       "         842.14959462,  745.92202238]),\n",
       " (10,))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sigma, Sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-9.66500802e-23,  8.03249032e-02,  3.47713180e-02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  4.09393790e-05],\n",
       "        [ 1.08951139e-15, -4.59886344e-02, -5.01911417e-02, ...,\n",
       "         -0.00000000e+00, -0.00000000e+00,  6.09754782e-05],\n",
       "        [ 1.22510161e-16, -1.07427744e-02, -2.15773801e-02, ...,\n",
       "         -0.00000000e+00, -0.00000000e+00,  1.81983497e-05],\n",
       "        ...,\n",
       "        [ 6.92310829e-18,  1.46867327e-01,  2.48880332e-02, ...,\n",
       "         -0.00000000e+00, -0.00000000e+00,  1.05590768e-04],\n",
       "        [-1.97325516e-16, -3.95941440e-02, -2.90838378e-02, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  9.09046228e-05],\n",
       "        [-1.02736231e-17, -6.43463256e-03, -4.06747689e-05, ...,\n",
       "          0.00000000e+00,  0.00000000e+00,  2.61423612e-05]]),\n",
       " (10, 65134))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT, VT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 65134)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing a prediction\n",
    "\n",
    "So, how do we transform the matrices $U_t$, $\\Sigma_t$, $V^T_t$ into something that we can use for recommendation? \n",
    "\n",
    "Remember, $\\widehat{URM} = U_t \\Sigma_t V^T_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matrix Factorization Approach (PureSVDRecommender)\n",
    "\n",
    "Consider the following matrices $W = U_t \\Sigma_t$, and $H = V^T_t$, then we just have a Matrix Factorization recommender where $\\widehat{URM} = WH$, where $W$ represents the user factors and $H$ are the item factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store an intermediate pre-multiplied matrix\n",
    "user_factors = U * sps.diags(Sigma)\n",
    "item_factors = VT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now predict if Bob would like Toy Story or not..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction is 0.03\n"
     ]
    }
   ],
   "source": [
    "prediction = user_factors[user_index, :].dot(item_factors[:,item_index])\n",
    "\n",
    "print(\"Prediction is {:.2f}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And with this we calculate the score of all items for Bob."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.09152789e-15,  7.47375230e-01,  4.49327415e-01, ...,\n",
       "        0.00000000e+00,  0.00000000e+00,  3.19772604e-04])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores = user_factors[user_index, :].dot(item_factors)\n",
    "item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65134,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which are the best 20 items for Bob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([588, 595, 364, 356, 150, 590, 500, 539,  34, 480, 597, 457,   1,\n",
       "       339, 592, 587, 919, 594, 357, 318])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_items_for_bob = np.flip(np.argsort(item_scores))[:20]\n",
    "best_items_for_bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Toy story inside that list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_index in best_items_for_bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item-Based Approach (PureSVDItemRecommender)\n",
    "\n",
    "Consider the following matrix $P = U_t \\Sigma_t$.\n",
    "\n",
    "As $U$ and $V^T$ are orthogonal (meaning $UU^T = U^TU = I$), then \n",
    "\n",
    "$$ \\widehat{URM} = U_t \\Sigma_t V^T_t $$\n",
    "$$ \\widehat{URM}V = U_t \\Sigma_t V^T_t V $$\n",
    "$$ \\widehat{URM}V = U_t \\Sigma_t $$\n",
    "\n",
    "Re-arranging the equations\n",
    "\n",
    "$$ P = U_t \\Sigma_t = URMV $$\n",
    "\n",
    "With this, if we define $r_u$ as the $u$-th row in the URM and $v^T_i$ as the $i$-th column in $V^T$ then we calculate any $\\hat{r}_{u,i}$ as \n",
    "\n",
    "$$\\hat{r}_{u,i} = r_u V v^T_i$$\n",
    "\n",
    "Which is equivalent to having a similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BEWARE: This consumes A LOT of memory\n",
    "item_weights = np.dot(VT.T, VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min, sys: 15 s, total: 2min 16s\n",
      "Wall time: 34.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ITEM_factors = VT.T\n",
    "topK = 100\n",
    "\n",
    "n_items, n_factors = ITEM_factors.shape\n",
    "\n",
    "block_size = 100\n",
    "\n",
    "start_item = 0\n",
    "end_item = 0\n",
    "\n",
    "values = []\n",
    "rows = []\n",
    "cols = []\n",
    "\n",
    "# Compute all similarities for each item using vectorization\n",
    "while start_item < n_items:\n",
    "\n",
    "    end_item = min(n_items, start_item + block_size)\n",
    "\n",
    "    this_block_weight = np.dot(ITEM_factors[start_item:end_item, :], ITEM_factors.T)\n",
    "\n",
    "    for col_index_in_block in range(this_block_weight.shape[0]):\n",
    "\n",
    "        this_column_weights = this_block_weight[col_index_in_block, :]\n",
    "        item_original_index = start_item + col_index_in_block\n",
    "\n",
    "        # Sort indices and select TopK\n",
    "        # Sorting is done in three steps. Faster then plain np.argsort for higher number of items\n",
    "        # - Partition the data to extract the set of relevant items\n",
    "        # - Sort only the relevant items\n",
    "        # - Get the original item index\n",
    "        relevant_items_partition = (-this_column_weights).argpartition(topK-1)[0:topK]\n",
    "        relevant_items_partition_sorting = np.argsort(-this_column_weights[relevant_items_partition])\n",
    "        top_k_idx = relevant_items_partition[relevant_items_partition_sorting]\n",
    "\n",
    "        # Incrementally build sparse matrix, do not add zeros\n",
    "        notZerosMask = this_column_weights[top_k_idx] != 0.0\n",
    "        numNotZeros = np.sum(notZerosMask)\n",
    "\n",
    "        values.extend(this_column_weights[top_k_idx][notZerosMask])\n",
    "        rows.extend(top_k_idx[notZerosMask])\n",
    "        cols.extend(np.ones(numNotZeros) * item_original_index)\n",
    "\n",
    "\n",
    "\n",
    "    start_item += block_size\n",
    "\n",
    "item_weights = sps.csr_matrix((values, (rows, cols)),\n",
    "                          shape=(n_items, n_items),\n",
    "                          dtype=np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<65134x65134 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 1066100 stored elements in Compressed Sparse Row format>,\n",
       " (65134, 65134))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_weights, item_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.72765353e-16, 5.57427854e-01, 3.55230400e-01, ...,\n",
       "       0.00000000e+00, 0.00000000e+00, 5.08874036e-05])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores = URM_train[user_index, :].dot(item_weights).A.flatten()\n",
    "item_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65134,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, which are the best 20 items for Bob?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([588, 595, 364, 150, 356, 590, 457, 539, 480,  34, 500, 318, 339,\n",
       "       597, 380, 592, 593, 587, 594, 110])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_items_for_bob = np.flip(np.argsort(item_scores))[:20]\n",
    "best_items_for_bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Toy story inside that list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_index in best_items_for_bob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison: BPR, FunkSVD, PureSVD (MF and Item-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MatrixFactorization.Cython.MatrixFactorization_Cython import MatrixFactorization_BPR_Cython, MatrixFactorization_FunkSVD_Cython\n",
    "from MatrixFactorization.PureSVDRecommender import PureSVDRecommender, PureSVDItemRecommender\n",
    "\n",
    "from Base.Evaluation.Evaluator import EvaluatorHoldout\n",
    "\n",
    "evaluator_test = EvaluatorHoldout(URM_test, cutoff_list=[5, 20])\n",
    "\n",
    "evaluator_validation_early_stopping = EvaluatorHoldout(URM_train, cutoff_list=[5], exclude_seen = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization_BPR_Cython_Recommender: URM Detected 1690 (2.36 %) cold users.\n",
      "MatrixFactorization_BPR_Cython_Recommender: URM Detected 54474 (83.63 %) cold items.\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.61 seconds. BPR loss 1.00E-02. Sample per second: 115882\n",
      "MF_BPR: Epoch 1 of 300. Elapsed time 0.57 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.09 seconds. BPR loss 1.01E-02. Sample per second: 65374\n",
      "MF_BPR: Epoch 2 of 300. Elapsed time 1.05 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.57 seconds. BPR loss 1.03E-02. Sample per second: 124329\n",
      "MF_BPR: Epoch 3 of 300. Elapsed time 1.53 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.05 seconds. BPR loss 1.01E-02. Sample per second: 67560\n",
      "MF_BPR: Epoch 4 of 300. Elapsed time 2.01 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.54 seconds. BPR loss 1.01E-02. Sample per second: 130973\n",
      "MF_BPR: Epoch 5 of 300. Elapsed time 2.50 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.02 seconds. BPR loss 9.99E-03. Sample per second: 69343\n",
      "MF_BPR: Epoch 6 of 300. Elapsed time 2.98 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.51 seconds. BPR loss 9.98E-03. Sample per second: 140397\n",
      "MF_BPR: Epoch 7 of 300. Elapsed time 3.46 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.00 seconds. BPR loss 1.01E-02. Sample per second: 71053\n",
      "MF_BPR: Epoch 8 of 300. Elapsed time 3.96 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.49 seconds. BPR loss 1.01E-02. Sample per second: 146112\n",
      "MF_BPR: Epoch 9 of 300. Elapsed time 4.44 sec\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.97 seconds. BPR loss 1.01E-02. Sample per second: 72922\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17000 ( 24.33% ) in 30.21 sec. Users per second: 563\n",
      "EvaluatorHoldout: Processed 32000 ( 45.79% ) in 1.01 min. Users per second: 527\n",
      "EvaluatorHoldout: Processed 48000 ( 68.69% ) in 1.54 min. Users per second: 521\n",
      "EvaluatorHoldout: Processed 64000 ( 91.59% ) in 2.06 min. Users per second: 517\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.25 min. Users per second: 517\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041334, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007598, MRR: 0.0037687, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037837, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480486, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637670, SHANNON_ENTROPY: 14.4217609, \n",
      "\n",
      "MF_BPR: New best model found! Updating.\n",
      "MF_BPR: Epoch 10 of 300. Elapsed time 2.34 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.86 seconds. BPR loss 1.01E-02. Sample per second: 82574\n",
      "MF_BPR: Epoch 11 of 300. Elapsed time 2.35 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.36 seconds. BPR loss 1.01E-02. Sample per second: 52384\n",
      "MF_BPR: Epoch 12 of 300. Elapsed time 2.36 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.84 seconds. BPR loss 9.96E-03. Sample per second: 84489\n",
      "MF_BPR: Epoch 13 of 300. Elapsed time 2.36 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.33 seconds. BPR loss 1.00E-02. Sample per second: 53551\n",
      "MF_BPR: Epoch 14 of 300. Elapsed time 2.37 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.89 seconds. BPR loss 1.02E-02. Sample per second: 79628\n",
      "MF_BPR: Epoch 15 of 300. Elapsed time 2.38 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.44 seconds. BPR loss 1.02E-02. Sample per second: 49178\n",
      "MF_BPR: Epoch 16 of 300. Elapsed time 2.39 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.04 seconds. BPR loss 1.00E-02. Sample per second: 68450\n",
      "MF_BPR: Epoch 17 of 300. Elapsed time 2.40 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.66 seconds. BPR loss 1.01E-02. Sample per second: 107276\n",
      "MF_BPR: Epoch 18 of 300. Elapsed time 2.41 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.29 seconds. BPR loss 1.01E-02. Sample per second: 55016\n",
      "MF_BPR: Epoch 19 of 300. Elapsed time 2.42 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.92 seconds. BPR loss 1.01E-02. Sample per second: 77143\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17000 ( 24.33% ) in 30.89 sec. Users per second: 550\n",
      "EvaluatorHoldout: Processed 35000 ( 50.09% ) in 1.03 min. Users per second: 564\n",
      "EvaluatorHoldout: Processed 53000 ( 75.85% ) in 1.56 min. Users per second: 566\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.05 min. Users per second: 569\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041334, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007598, MRR: 0.0037687, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037837, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480486, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637673, SHANNON_ENTROPY: 14.4217616, \n",
      "\n",
      "MF_BPR: Epoch 20 of 300. Elapsed time 4.48 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.31 seconds. BPR loss 1.01E-02. Sample per second: 54250\n",
      "MF_BPR: Epoch 21 of 300. Elapsed time 4.49 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.80 seconds. BPR loss 1.01E-02. Sample per second: 89252\n",
      "MF_BPR: Epoch 22 of 300. Elapsed time 4.50 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.27 seconds. BPR loss 1.02E-02. Sample per second: 55697\n",
      "MF_BPR: Epoch 23 of 300. Elapsed time 4.50 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.76 seconds. BPR loss 1.00E-02. Sample per second: 93942\n",
      "MF_BPR: Epoch 24 of 300. Elapsed time 4.51 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.24 seconds. BPR loss 1.00E-02. Sample per second: 57347\n",
      "MF_BPR: Epoch 25 of 300. Elapsed time 4.52 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.72 seconds. BPR loss 1.00E-02. Sample per second: 98326\n",
      "MF_BPR: Epoch 26 of 300. Elapsed time 4.53 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.22 seconds. BPR loss 1.00E-02. Sample per second: 58331\n",
      "MF_BPR: Epoch 27 of 300. Elapsed time 4.54 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.70 seconds. BPR loss 1.01E-02. Sample per second: 101051\n",
      "MF_BPR: Epoch 28 of 300. Elapsed time 4.54 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.19 seconds. BPR loss 1.01E-02. Sample per second: 59668\n",
      "MF_BPR: Epoch 29 of 300. Elapsed time 4.55 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.68 seconds. BPR loss 1.00E-02. Sample per second: 104070\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17000 ( 24.33% ) in 31.54 sec. Users per second: 539\n",
      "EvaluatorHoldout: Processed 35000 ( 50.09% ) in 1.05 min. Users per second: 557\n",
      "EvaluatorHoldout: Processed 53000 ( 75.85% ) in 1.57 min. Users per second: 562\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.07 min. Users per second: 564\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041334, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007598, MRR: 0.0037687, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037837, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480333, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637648, SHANNON_ENTROPY: 14.4217491, \n",
      "\n",
      "MF_BPR: Epoch 30 of 300. Elapsed time 6.63 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.27 seconds. BPR loss 9.98E-03. Sample per second: 55945\n",
      "MF_BPR: Epoch 31 of 300. Elapsed time 6.64 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.76 seconds. BPR loss 1.02E-02. Sample per second: 93158\n",
      "MF_BPR: Epoch 32 of 300. Elapsed time 6.65 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.26 seconds. BPR loss 1.01E-02. Sample per second: 56278\n",
      "MF_BPR: Epoch 33 of 300. Elapsed time 6.65 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.75 seconds. BPR loss 1.02E-02. Sample per second: 94657\n",
      "MF_BPR: Epoch 34 of 300. Elapsed time 6.66 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.24 seconds. BPR loss 1.00E-02. Sample per second: 57229\n",
      "MF_BPR: Epoch 35 of 300. Elapsed time 6.67 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.74 seconds. BPR loss 9.98E-03. Sample per second: 96085\n",
      "MF_BPR: Epoch 36 of 300. Elapsed time 6.68 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.26 seconds. BPR loss 1.01E-02. Sample per second: 56548\n",
      "MF_BPR: Epoch 37 of 300. Elapsed time 6.69 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.75 seconds. BPR loss 1.00E-02. Sample per second: 94960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MF_BPR: Epoch 38 of 300. Elapsed time 6.70 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.23 seconds. BPR loss 1.02E-02. Sample per second: 57630\n",
      "MF_BPR: Epoch 39 of 300. Elapsed time 6.70 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.72 seconds. BPR loss 1.00E-02. Sample per second: 98681\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 17000 ( 24.33% ) in 30.26 sec. Users per second: 562\n",
      "EvaluatorHoldout: Processed 34000 ( 48.66% ) in 1.01 min. Users per second: 560\n",
      "EvaluatorHoldout: Processed 51000 ( 72.98% ) in 1.52 min. Users per second: 559\n",
      "EvaluatorHoldout: Processed 68000 ( 97.31% ) in 2.03 min. Users per second: 559\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.08 min. Users per second: 559\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041334, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007598, MRR: 0.0037687, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037837, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480333, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637648, SHANNON_ENTROPY: 14.4217491, \n",
      "\n",
      "MF_BPR: Epoch 40 of 300. Elapsed time 8.79 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.22 seconds. BPR loss 9.98E-03. Sample per second: 58122\n",
      "MF_BPR: Epoch 41 of 300. Elapsed time 8.80 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.73 seconds. BPR loss 1.02E-02. Sample per second: 97625\n",
      "MF_BPR: Epoch 42 of 300. Elapsed time 8.81 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.21 seconds. BPR loss 1.00E-02. Sample per second: 58462\n",
      "MF_BPR: Epoch 43 of 300. Elapsed time 8.82 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.69 seconds. BPR loss 1.01E-02. Sample per second: 102432\n",
      "MF_BPR: Epoch 44 of 300. Elapsed time 8.83 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.18 seconds. BPR loss 1.01E-02. Sample per second: 60109\n",
      "MF_BPR: Epoch 45 of 300. Elapsed time 8.84 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.66 seconds. BPR loss 1.01E-02. Sample per second: 107723\n",
      "MF_BPR: Epoch 46 of 300. Elapsed time 8.84 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.13 seconds. BPR loss 1.01E-02. Sample per second: 62770\n",
      "MF_BPR: Epoch 47 of 300. Elapsed time 8.85 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.60 seconds. BPR loss 1.00E-02. Sample per second: 117662\n",
      "MF_BPR: Epoch 48 of 300. Elapsed time 8.86 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.08 seconds. BPR loss 1.01E-02. Sample per second: 65732\n",
      "MF_BPR: Epoch 49 of 300. Elapsed time 8.87 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.56 seconds. BPR loss 1.01E-02. Sample per second: 126986\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 16000 ( 22.90% ) in 30.75 sec. Users per second: 520\n",
      "EvaluatorHoldout: Processed 31000 ( 44.36% ) in 1.02 min. Users per second: 504\n",
      "EvaluatorHoldout: Processed 47000 ( 67.26% ) in 1.55 min. Users per second: 505\n",
      "EvaluatorHoldout: Processed 62000 ( 88.73% ) in 2.07 min. Users per second: 499\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.32 min. Users per second: 503\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041298, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007596, MRR: 0.0037680, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037830, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480333, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637626, SHANNON_ENTROPY: 14.4217344, \n",
      "\n",
      "MF_BPR: Epoch 50 of 300. Elapsed time 11.19 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.17 seconds. BPR loss 1.01E-02. Sample per second: 60478\n",
      "MF_BPR: Epoch 51 of 300. Elapsed time 11.20 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.67 seconds. BPR loss 1.01E-02. Sample per second: 106415\n",
      "MF_BPR: Epoch 52 of 300. Elapsed time 11.21 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.14 seconds. BPR loss 1.01E-02. Sample per second: 62020\n",
      "MF_BPR: Epoch 53 of 300. Elapsed time 11.22 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.74 seconds. BPR loss 1.00E-02. Sample per second: 95859\n",
      "MF_BPR: Epoch 54 of 300. Elapsed time 11.23 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.26 seconds. BPR loss 1.01E-02. Sample per second: 56534\n",
      "MF_BPR: Epoch 55 of 300. Elapsed time 11.24 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.74 seconds. BPR loss 1.01E-02. Sample per second: 96389\n",
      "MF_BPR: Epoch 56 of 300. Elapsed time 11.24 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.43 seconds. BPR loss 1.00E-02. Sample per second: 49519\n",
      "MF_BPR: Epoch 57 of 300. Elapsed time 11.26 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 0.98 seconds. BPR loss 1.01E-02. Sample per second: 72246\n",
      "MF_BPR: Epoch 58 of 300. Elapsed time 11.27 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.53 seconds. BPR loss 1.00E-02. Sample per second: 46344\n",
      "MF_BPR: Epoch 59 of 300. Elapsed time 11.27 min\n",
      "MF_BPR: Processed 71000 ( 98.61% ) in 1.14 seconds. BPR loss 1.00E-02. Sample per second: 62542\n",
      "MF_BPR: Validation begins...\n",
      "EvaluatorHoldout: Processed 15000 ( 21.47% ) in 30.44 sec. Users per second: 493\n",
      "EvaluatorHoldout: Processed 30000 ( 42.93% ) in 1.01 min. Users per second: 495\n",
      "EvaluatorHoldout: Processed 47000 ( 67.26% ) in 1.53 min. Users per second: 511\n",
      "EvaluatorHoldout: Processed 63000 ( 90.16% ) in 2.06 min. Users per second: 510\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.29 min. Users per second: 509\n",
      "MF_BPR: CUTOFF: 5 - ROC_AUC: 0.0041334, PRECISION: 0.0016514, PRECISION_RECALL_MIN_DEN: 0.0016514, RECALL: 0.0000687, MAP: 0.0007598, MRR: 0.0037687, NDCG: 0.0001397, F1: 0.0001318, HIT_RATE: 0.0082572, ARHR: 0.0037837, NOVELTY: 0.0001948, AVERAGE_POPULARITY: 0.0040914, DIVERSITY_MEAN_INTER_LIST: 0.9996324, DIVERSITY_HERFINDAHL: 0.9999236, COVERAGE_ITEM: 0.6480333, COVERAGE_ITEM_CORRECT: 0.0058648, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.0079924, DIVERSITY_GINI: 0.2637659, SHANNON_ENTROPY: 14.4217517, \n",
      "\n",
      "MF_BPR: Convergence reached! Terminating at epoch 60. Best value for 'MAP' at epoch 10 is 0.0008. Elapsed time 13.57 min\n",
      "MF_BPR: Epoch 60 of 300. Elapsed time 13.57 min\n",
      "EvaluatorHoldout: Processed 16000 ( 22.92% ) in 31.70 sec. Users per second: 505\n",
      "EvaluatorHoldout: Processed 31000 ( 44.41% ) in 1.06 min. Users per second: 487\n",
      "EvaluatorHoldout: Processed 48000 ( 68.77% ) in 1.57 min. Users per second: 511\n",
      "EvaluatorHoldout: Processed 65000 ( 93.13% ) in 2.10 min. Users per second: 517\n",
      "EvaluatorHoldout: Processed 69797 ( 100.00% ) in 2.25 min. Users per second: 517\n",
      "CPU times: user 17min 54s, sys: 4min 47s, total: 22min 41s\n",
      "Wall time: 15min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommender = MatrixFactorization_BPR_Cython(URM_train)\n",
    "recommender.fit(num_factors = 50, \n",
    "                validation_every_n = 10, \n",
    "                stop_on_validation = True, \n",
    "                evaluator_object = evaluator_validation_early_stopping,\n",
    "                lower_validations_allowed = 5, \n",
    "                validation_metric = \"MAP\")\n",
    "\n",
    "result_dict_bpr, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'ROC_AUC': 0.0010100720661346476,\n",
       "  'PRECISION': 0.00042408699514305667,\n",
       "  'PRECISION_RECALL_MIN_DEN': 0.00042408699514305667,\n",
       "  'RECALL': 7.75067813970793e-05,\n",
       "  'MAP': 0.00018338897087267329,\n",
       "  'MRR': 0.0009169448543633686,\n",
       "  'NDCG': 9.491978219305602e-05,\n",
       "  'F1': 0.0001310607091364779,\n",
       "  'HIT_RATE': 0.0021204349757152885,\n",
       "  'ARHR': 0.0009169448543633686,\n",
       "  'NOVELTY': 0.00019375210648446824,\n",
       "  'AVERAGE_POPULARITY': 0.003778208868346232,\n",
       "  'DIVERSITY_MEAN_INTER_LIST': 0.9996324846340346,\n",
       "  'DIVERSITY_HERFINDAHL': 0.9999236325272349,\n",
       "  'COVERAGE_ITEM': 0.647925814474775,\n",
       "  'COVERAGE_ITEM_CORRECT': 0.002011238370129272,\n",
       "  'COVERAGE_USER': 0.975254303599374,\n",
       "  'COVERAGE_USER_CORRECT': 0.0020679633355689692,\n",
       "  'DIVERSITY_GINI': 0.2637144216269709,\n",
       "  'SHANNON_ENTROPY': 14.421565887645292}}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_bpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatrixFactorization_FunkSVD_Cython_Recommender: URM Detected 1690 (2.36 %) cold users.\n",
      "MatrixFactorization_FunkSVD_Cython_Recommender: URM Detected 54474 (83.63 %) cold items.\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.69 seconds. MSE loss 1.96E+00. Sample per second: 217996\n",
      "FUNK_SVD: Epoch 1 of 300. Elapsed time 35.76 sec\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.78 seconds. MSE loss 1.13E+00. Sample per second: 217480\n",
      "FUNK_SVD: Epoch 2 of 300. Elapsed time 1.20 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 38.09 seconds. MSE loss 1.13E+00. Sample per second: 209990\n",
      "FUNK_SVD: Epoch 3 of 300. Elapsed time 1.82 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.09 seconds. MSE loss 1.13E+00. Sample per second: 221664\n",
      "FUNK_SVD: Epoch 4 of 300. Elapsed time 2.42 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.58 seconds. MSE loss 1.13E+00. Sample per second: 231329\n",
      "FUNK_SVD: Epoch 5 of 300. Elapsed time 2.99 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.65 seconds. MSE loss 1.12E+00. Sample per second: 230862\n",
      "FUNK_SVD: Epoch 6 of 300. Elapsed time 3.56 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.42 seconds. MSE loss 1.12E+00. Sample per second: 225816\n",
      "FUNK_SVD: Epoch 7 of 300. Elapsed time 4.14 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.75 seconds. MSE loss 1.12E+00. Sample per second: 230160\n",
      "FUNK_SVD: Epoch 8 of 300. Elapsed time 4.71 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.83 seconds. MSE loss 1.11E+00. Sample per second: 229676\n",
      "FUNK_SVD: Epoch 9 of 300. Elapsed time 5.28 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.68 seconds. MSE loss 1.11E+00. Sample per second: 230652\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 15000 ( 21.47% ) in 30.85 sec. Users per second: 486\n",
      "EvaluatorHoldout: Processed 30000 ( 42.93% ) in 1.03 min. Users per second: 486\n",
      "EvaluatorHoldout: Processed 45000 ( 64.40% ) in 1.54 min. Users per second: 486\n",
      "EvaluatorHoldout: Processed 60000 ( 85.86% ) in 2.06 min. Users per second: 485\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.40 min. Users per second: 485\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3799515, PRECISION: 0.1777154, PRECISION_RECALL_MIN_DEN: 0.1777154, RECALL: 0.0137061, MAP: 0.1312556, MRR: 0.3982918, NDCG: 0.0438005, F1: 0.0254494, HIT_RATE: 0.8885772, ARHR: 0.5126282, NOVELTY: 0.0004353, AVERAGE_POPULARITY: 0.4444546, DIVERSITY_MEAN_INTER_LIST: 0.8083752, DIVERSITY_HERFINDAHL: 0.9616727, COVERAGE_ITEM: 0.4897749, COVERAGE_ITEM_CORRECT: 0.0044370, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.5334926, DIVERSITY_GINI: 0.1011513, SHANNON_ENTROPY: 9.5423481, \n",
      "\n",
      "FUNK_SVD: New best model found! Updating.\n",
      "FUNK_SVD: Epoch 10 of 300. Elapsed time 8.25 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.88 seconds. MSE loss 1.11E+00. Sample per second: 229310\n",
      "FUNK_SVD: Epoch 11 of 300. Elapsed time 8.82 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.19 seconds. MSE loss 1.11E+00. Sample per second: 227304\n",
      "FUNK_SVD: Epoch 12 of 300. Elapsed time 9.39 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.20 seconds. MSE loss 1.10E+00. Sample per second: 233873\n",
      "FUNK_SVD: Epoch 13 of 300. Elapsed time 9.95 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.39 seconds. MSE loss 1.10E+00. Sample per second: 232621\n",
      "FUNK_SVD: Epoch 14 of 300. Elapsed time 10.52 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.24 seconds. MSE loss 1.10E+00. Sample per second: 233646\n",
      "FUNK_SVD: Epoch 15 of 300. Elapsed time 11.09 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 33.96 seconds. MSE loss 1.10E+00. Sample per second: 235538\n",
      "FUNK_SVD: Epoch 16 of 300. Elapsed time 11.65 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 37.44 seconds. MSE loss 1.09E+00. Sample per second: 213635\n",
      "FUNK_SVD: Epoch 17 of 300. Elapsed time 12.26 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.29 seconds. MSE loss 1.09E+00. Sample per second: 226669\n",
      "FUNK_SVD: Epoch 18 of 300. Elapsed time 12.84 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.38 seconds. MSE loss 1.09E+00. Sample per second: 226084\n",
      "FUNK_SVD: Epoch 19 of 300. Elapsed time 13.42 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 39.67 seconds. MSE loss 1.09E+00. Sample per second: 201664\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 14000 ( 20.03% ) in 31.14 sec. Users per second: 450\n",
      "EvaluatorHoldout: Processed 29000 ( 41.50% ) in 1.04 min. Users per second: 465\n",
      "EvaluatorHoldout: Processed 42000 ( 60.10% ) in 1.54 min. Users per second: 455\n",
      "EvaluatorHoldout: Processed 55000 ( 78.71% ) in 2.07 min. Users per second: 443\n",
      "EvaluatorHoldout: Processed 66000 ( 94.45% ) in 2.58 min. Users per second: 426\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.73 min. Users per second: 426\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3914990, PRECISION: 0.3263602, PRECISION_RECALL_MIN_DEN: 0.3263602, RECALL: 0.0249131, MAP: 0.2386797, MRR: 0.4870112, NDCG: 0.0704534, F1: 0.0462923, HIT_RATE: 1.6318011, ARHR: 0.7669152, NOVELTY: 0.0006428, AVERAGE_POPULARITY: 0.8177716, DIVERSITY_MEAN_INTER_LIST: 0.4322747, DIVERSITY_HERFINDAHL: 0.8864537, COVERAGE_ITEM: 0.0522615, COVERAGE_ITEM_CORRECT: 0.0012129, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.6966801, DIVERSITY_GINI: 0.0006949, SHANNON_ENTROPY: 3.7187564, \n",
      "\n",
      "FUNK_SVD: New best model found! Updating.\n",
      "FUNK_SVD: Epoch 20 of 300. Elapsed time 16.81 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 39.26 seconds. MSE loss 1.09E+00. Sample per second: 203750\n",
      "FUNK_SVD: Epoch 21 of 300. Elapsed time 17.46 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 37.96 seconds. MSE loss 1.08E+00. Sample per second: 210702\n",
      "FUNK_SVD: Epoch 22 of 300. Elapsed time 18.08 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 42.20 seconds. MSE loss 1.08E+00. Sample per second: 189536\n",
      "FUNK_SVD: Epoch 23 of 300. Elapsed time 18.77 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.58 seconds. MSE loss 1.08E+00. Sample per second: 218658\n",
      "FUNK_SVD: Epoch 24 of 300. Elapsed time 19.38 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.20 seconds. MSE loss 1.08E+00. Sample per second: 220953\n",
      "FUNK_SVD: Epoch 25 of 300. Elapsed time 19.97 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.54 seconds. MSE loss 1.08E+00. Sample per second: 225096\n",
      "FUNK_SVD: Epoch 26 of 300. Elapsed time 20.56 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.35 seconds. MSE loss 1.08E+00. Sample per second: 226300\n",
      "FUNK_SVD: Epoch 27 of 300. Elapsed time 21.14 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.11 seconds. MSE loss 1.08E+00. Sample per second: 227814\n",
      "FUNK_SVD: Epoch 28 of 300. Elapsed time 21.72 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 39.58 seconds. MSE loss 1.07E+00. Sample per second: 202091\n",
      "FUNK_SVD: Epoch 29 of 300. Elapsed time 22.38 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 39.47 seconds. MSE loss 1.07E+00. Sample per second: 202638\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 13000 ( 18.60% ) in 30.48 sec. Users per second: 427\n",
      "EvaluatorHoldout: Processed 27000 ( 38.64% ) in 1.03 min. Users per second: 436\n",
      "EvaluatorHoldout: Processed 40000 ( 57.24% ) in 1.54 min. Users per second: 433\n",
      "EvaluatorHoldout: Processed 54000 ( 77.28% ) in 2.06 min. Users per second: 436\n",
      "EvaluatorHoldout: Processed 68000 ( 97.31% ) in 2.57 min. Users per second: 441\n",
      "EvaluatorHoldout: Processed 69878 ( 100.00% ) in 2.64 min. Users per second: 441\n",
      "FUNK_SVD: CUTOFF: 5 - ROC_AUC: 0.3847086, PRECISION: 0.3267094, PRECISION_RECALL_MIN_DEN: 0.3267094, RECALL: 0.0247816, MAP: 0.2380830, MRR: 0.4851308, NDCG: 0.0707682, F1: 0.0460687, HIT_RATE: 1.6335470, ARHR: 0.7638923, NOVELTY: 0.0006500, AVERAGE_POPULARITY: 0.8190409, DIVERSITY_MEAN_INTER_LIST: 0.3614325, DIVERSITY_HERFINDAHL: 0.8722855, COVERAGE_ITEM: 0.0016428, COVERAGE_ITEM_CORRECT: 0.0006909, COVERAGE_USER: 0.9763861, COVERAGE_USER_CORRECT: 0.6970294, DIVERSITY_GINI: 0.0001303, SHANNON_ENTROPY: 3.3196124, \n",
      "\n",
      "FUNK_SVD: Epoch 30 of 300. Elapsed time 25.67 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 38.23 seconds. MSE loss 1.07E+00. Sample per second: 209240\n",
      "FUNK_SVD: Epoch 31 of 300. Elapsed time 26.30 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 37.71 seconds. MSE loss 1.07E+00. Sample per second: 212091\n",
      "FUNK_SVD: Epoch 32 of 300. Elapsed time 26.93 min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 37.83 seconds. MSE loss 1.07E+00. Sample per second: 211444\n",
      "FUNK_SVD: Epoch 33 of 300. Elapsed time 27.55 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 38.35 seconds. MSE loss 1.07E+00. Sample per second: 208584\n",
      "FUNK_SVD: Epoch 34 of 300. Elapsed time 28.17 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 35.09 seconds. MSE loss 1.07E+00. Sample per second: 227988\n",
      "FUNK_SVD: Epoch 35 of 300. Elapsed time 28.75 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.55 seconds. MSE loss 1.07E+00. Sample per second: 231512\n",
      "FUNK_SVD: Epoch 36 of 300. Elapsed time 29.33 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 34.88 seconds. MSE loss 1.07E+00. Sample per second: 229318\n",
      "FUNK_SVD: Epoch 37 of 300. Elapsed time 29.90 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 36.44 seconds. MSE loss 1.06E+00. Sample per second: 219506\n",
      "FUNK_SVD: Epoch 38 of 300. Elapsed time 30.49 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 37.62 seconds. MSE loss 1.06E+00. Sample per second: 212630\n",
      "FUNK_SVD: Epoch 39 of 300. Elapsed time 31.11 min\n",
      "FUNK_SVD: Processed 7999000 ( 99.99% ) in 38.87 seconds. MSE loss 1.06E+00. Sample per second: 205810\n",
      "FUNK_SVD: Validation begins...\n",
      "EvaluatorHoldout: Processed 13000 ( 18.60% ) in 31.31 sec. Users per second: 415\n",
      "EvaluatorHoldout: Processed 26000 ( 37.21% ) in 1.03 min. Users per second: 419\n",
      "EvaluatorHoldout: Processed 39000 ( 55.81% ) in 1.54 min. Users per second: 423\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/MatrixFactorization/Cython/MatrixFactorization_Cython.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, **key_args)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkey_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMatrixFactorization_FunkSVD_Cython\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkey_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/MatrixFactorization/Cython/MatrixFactorization_Cython.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, batch_size, num_factors, positive_threshold_BPR, learning_rate, use_bias, sgd_mode, negative_interactions_quota, init_mean, init_std_dev, user_reg, item_reg, bias_reg, positive_reg, negative_reg, random_seed, **earlystopping_kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m         self._train_with_early_stopping(epochs,\n\u001b[1;32m    108\u001b[0m                                         \u001b[0malgorithm_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                                         **earlystopping_kwargs)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/Base/Incremental_Training_Early_Stopping.py\u001b[0m in \u001b[0;36m_train_with_early_stopping\u001b[0;34m(self, epochs_max, epochs_min, validation_every_n, stop_on_validation, validation_metric, lower_validations_allowed, evaluator_object, algorithm_name)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m                 \u001b[0;31m# If the evaluator validation has multiple cutoffs, choose the first one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m                 \u001b[0mresults_run\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_run_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator_object\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluateRecommender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m                 \u001b[0mresults_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_run\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/Base/Evaluation/Evaluator.py\u001b[0m in \u001b[0;36mevaluateRecommender\u001b[0;34m(self, recommender_object)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_users_evaluated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mresults_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_evaluation_on_selected_users\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecommender_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musers_to_evaluate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/Base/Evaluation/Evaluator.py\u001b[0m in \u001b[0;36m_run_evaluation_on_selected_users\u001b[0;34m(self, recommender_object, users_to_evaluate, block_size)\u001b[0m\n\u001b[1;32m    447\u001b[0m                                                                       \u001b[0mremove_top_pop_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                                                                       \u001b[0mremove_custom_items_flag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_items_flag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m                                                                       \u001b[0mreturn_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m                                                                      )\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Development/polimi/RecSys_Course_AT_PoliMi/Base/BaseRecommender.py\u001b[0m in \u001b[0;36mrecommend\u001b[0;34m(self, user_id_array, cutoff, remove_seen_flag, items_to_compute, remove_top_pop_flag, remove_custom_items_flag, return_scores)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;31m# relevant_items_partition is block_size x cutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mrelevant_items_partition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mscores_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcutoff\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Get original value and sort it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommender = MatrixFactorization_FunkSVD_Cython(URM_train)\n",
    "recommender.fit(num_factors = 50, \n",
    "                validation_every_n = 10, \n",
    "                stop_on_validation = True, \n",
    "                evaluator_object = evaluator_validation_early_stopping,\n",
    "                lower_validations_allowed = 5, \n",
    "                validation_metric = \"MAP\")\n",
    "\n",
    "result_dict_funksvd, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_funksvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDRecommender: URM Detected 1690 (2.36 %) cold users.\n",
      "PureSVDRecommender: URM Detected 54474 (83.63 %) cold items.\n",
      "PureSVDRecommender: Computing SVD decomposition...\n",
      "PureSVDRecommender: Computing SVD decomposition... Done!\n",
      "EvaluatorHoldout: Processed 24000 ( 34.39% ) in 30.83 sec. Users per second: 779\n",
      "EvaluatorHoldout: Processed 48000 ( 68.77% ) in 1.02 min. Users per second: 786\n",
      "EvaluatorHoldout: Processed 69797 ( 100.00% ) in 1.48 min. Users per second: 786\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "recommender = PureSVDRecommender(URM_train)\n",
    "recommender.fit()\n",
    "\n",
    "result_dict_puresvd, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'ROC_AUC': 0.48907307381883197,\n",
       "  'PRECISION': 0.35991231714838107,\n",
       "  'PRECISION_RECALL_MIN_DEN': 0.36728250020303227,\n",
       "  'RECALL': 0.11248858385217032,\n",
       "  'MAP': 0.29162513352214264,\n",
       "  'MRR': 0.5744876809413961,\n",
       "  'NDCG': 0.16238128250526015,\n",
       "  'F1': 0.17140537531247144,\n",
       "  'HIT_RATE': 1.7995615857415075,\n",
       "  'ARHR': 0.906669579876837,\n",
       "  'NOVELTY': 0.0007497167569765295,\n",
       "  'AVERAGE_POPULARITY': 0.35303678253160586,\n",
       "  'DIVERSITY_MEAN_INTER_LIST': 0.9779994949173698,\n",
       "  'DIVERSITY_HERFINDAHL': 0.9955970965722101,\n",
       "  'COVERAGE_ITEM': 0.013387785181318513,\n",
       "  'COVERAGE_ITEM_CORRECT': 0.012865784382964351,\n",
       "  'COVERAGE_USER': 0.975254303599374,\n",
       "  'COVERAGE_USER_CORRECT': 0.7365023474178404,\n",
       "  'DIVERSITY_GINI': 0.003415266410567815,\n",
       "  'SHANNON_ENTROPY': 8.2286404658273}}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_puresvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PureSVDItemRecommender: URM Detected 1690 (2.36 %) cold users.\n",
      "PureSVDItemRecommender: URM Detected 54474 (83.63 %) cold items.\n",
      "PureSVDItemRecommender: Computing SVD decomposition...\n",
      "PureSVDItemRecommender: Computing SVD decomposition... Done!\n",
      "EvaluatorHoldout: Processed 8000 ( 11.46% ) in 31.80 sec. Users per second: 252\n",
      "EvaluatorHoldout: Processed 15000 ( 21.49% ) in 1.03 min. Users per second: 242\n",
      "EvaluatorHoldout: Processed 22000 ( 31.52% ) in 1.54 min. Users per second: 239\n",
      "EvaluatorHoldout: Processed 29000 ( 41.55% ) in 2.08 min. Users per second: 232\n",
      "EvaluatorHoldout: Processed 36000 ( 51.58% ) in 2.59 min. Users per second: 231\n",
      "EvaluatorHoldout: Processed 44000 ( 63.04% ) in 3.15 min. Users per second: 233\n",
      "EvaluatorHoldout: Processed 52000 ( 74.50% ) in 3.66 min. Users per second: 237\n",
      "EvaluatorHoldout: Processed 59000 ( 84.53% ) in 4.16 min. Users per second: 236\n",
      "EvaluatorHoldout: Processed 68000 ( 97.43% ) in 4.71 min. Users per second: 240\n",
      "EvaluatorHoldout: Processed 69797 ( 100.00% ) in 4.83 min. Users per second: 241\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "recommender = PureSVDItemRecommender(URM_train)\n",
    "recommender.fit()\n",
    "\n",
    "result_dict_puresvditem, _ = evaluator_test.evaluateRecommender(recommender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: {'ROC_AUC': 0.48989569752281503,\n",
       "  'PRECISION': 0.3593678811411037,\n",
       "  'PRECISION_RECALL_MIN_DEN': 0.36672731874824305,\n",
       "  'RECALL': 0.11210263546995451,\n",
       "  'MAP': 0.2915689348316569,\n",
       "  'MRR': 0.5752639798272129,\n",
       "  'NDCG': 0.1621333889225846,\n",
       "  'F1': 0.17089546497519495,\n",
       "  'HIT_RATE': 1.7968394057051162,\n",
       "  'ARHR': 0.9071364098743004,\n",
       "  'NOVELTY': 0.0007498457681226732,\n",
       "  'AVERAGE_POPULARITY': 0.3524201103185107,\n",
       "  'DIVERSITY_MEAN_INTER_LIST': 0.9778437497068952,\n",
       "  'DIVERSITY_HERFINDAHL': 0.9955659479763957,\n",
       "  'COVERAGE_ITEM': 0.013234255534743758,\n",
       "  'COVERAGE_ITEM_CORRECT': 0.012819725488991924,\n",
       "  'COVERAGE_USER': 0.975254303599374,\n",
       "  'COVERAGE_USER_CORRECT': 0.7364744019673597,\n",
       "  'DIVERSITY_GINI': 0.003400253611808011,\n",
       "  'SHANNON_ENTROPY': 8.222584521573335}}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict_puresvditem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra\n",
    "\n",
    "This section is for you to practice and analyze different aspects of what you saw in the notebook.\n",
    "\n",
    "1. The comparison we did was not fair in terms of parameters and their tuning. Run a hyperparameter tuning of the algorithms presented in the notebook and compare the best performant ones.\n",
    "\n",
    "2. Read about these other Matrix Factorization techniques:\n",
    " * Non Negative Matrix Factorization Recommender (NMFRecommender)\n",
    " * Binary/Implicit Alternating Least Squares (IALS) (IALSRecommender in the material)\n",
    " \n",
    " Familiarize yourself with these and compare them with what you've already know (BPR MF, FunkSVD, PureSVD, MF with PyTorch). What are the differences and similarities with what you've already seen?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
